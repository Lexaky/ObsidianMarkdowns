**Created at** [07-11-2025 22:50]
**Tags**: #Генетика #Без_градиента #ML
**Author**: Стрельцов А., *Искусственный Интеллект и Большие Данные*
![[Генетические_алгоритмы_logo.webp]]
# Генетические алгоритмы
**Генетический алгоритм** - это евгеника (*учение об отборе сильнейших*). Такие алгоритмы моделируют развитие некоторой **популяции** (эволюцию жизни). 
#### Рассматриваемое знание
*Генетический алгоритм* состоит из 3 этапов:
- Селекция
- Скрещивание (от англ. *crossover*)
- Мутация
**Целью** генетических алгоритмов является подбор параметров для функции $f$ ($fitness$ функция - *функция приспособленности*). 
Функция $f$ может быть чем угодно, состоять из любых переменных и параметров.
Параметрами функции называют некоторую зависимость от **генов** (или **хромосом**);
Решением задачи (набором параметров) называют **особей**; 
Множество решений задач называют **популяцией**.
##### Пример
Случайно заводим (*или они даются*) множество решений задачи. Моделируем, как популяция развивается.
Пусть есть популяция волков, живущих в лесу. Волки живут и умирают, с ними что-то происходит по мере жизни, некоторые из них более приспособлены к жизни в лесу, чем другие (какие-то вымрут, какие-то нет) - это называется **селекцией**.
- Как производится селекция? - **элитизм** (*элита*) - гарантированное сохранение небольшого числа лучших особей в следующем поколении популяции.
Может существовал волк, которого, например, сбили на дороге, а он лучше выбирал ягоды, чем другие волки. Хотим, чтобы он остался, чтобы сохранить ген для поиска ягод.
В данном примере:
- Особь - волк, ген - сбор ягод, популяция - стая волков.

**Генетика** - это творческий алгоритм. Придумываются алгоритмы, которые хорошо моделируют предметную область, которую мы хотим, - и они работают. Определённых алгоритмов нет для решения каждой генетической задачи, но есть некоторая часть из них, которые продемонстрировали нормальную работоспособность.

*Каким образом выбирать лучших особей?*
#### Турнирная селекция
Проводим много турниров. Выбираем из популяции $n$ $k$ особей случайно (подмножество из множества популяции, $k < n$). 
Турнир - это вероятность победить одну особь другой. В турнирах побеждают сильные (особи с лучшими генами), только они возвращаются в популяцию. После проведения турнира повторно берём $k$ особей, снова проводим турнир, снова победили сильные, вернули в популяцию. 
Таким образом, возвращаем в популяцию только сильных особей. У победы в турнире есть шанс, у сильных особей шанс победить выше. Турниры нужно выбирать так, чтобы шанс, что не повезёт победить сильной особи, был маленький.
*Минусы*: может существовать лучшая особь, которая не попала ни в один турнир и она просто вымрет. Необходимо ввести **элитизм** - сохранить какое-то число хороших особей, а остальных набрать турниром. Ввести турниры, где лучшие побеждают, например, с вероятностью $90\%$

В 1-й раз особь победит с вероятностью $p$, но могла проиграть с вероятностью $1 - p$,
поэтому 2-й раз особь, возможно, победит с вероятностью $p(1-p)$
в 3-й раз с вероятностью $p(1-p)^2$
$...$
в k-й раз победит с вероятностью $p(1-p)^{k-1}$

Наилучшая особь будет выигрывать часто.
#### Ранговая селекция
Посчитаем вероятность выбрать каждую особь:
$$p_i = \frac{f_i}{\sum_j f_j}$$
$f$ - исследуемая $fitness$ функция.
Самая приспособленная особь будет с большим шансом, а самая не приспособленная - с маленьким шансом. Выберем $n$ особей, учитывая вероятности (от большего к меньшей) - *каким образом?* - С помощью алгоритма SUS.
#### Алгоритм Stochastic Universal Sampling
Выбираем из всей популяции особей, а не из его какого-то диапазона популяции:
Данный алгоритм пытается выбрать из всей популяции особей примерно равномерное количество.
Выстраиваем особей по убыванию функции приспособленности f: $[ f0 \ |f1\ |..||]$
Введём понятие общей приспособленности: $F = \sum_j f_j$
- $k$ - сколько особей мы хотим выбрать
Вычисляем *шаг*: $step = \frac Fk$
Выбираем начальную позицию $start$ из отрезка $[0; step]$

![[Генетические_алгоритмы_steps.png]]

Смотрим, на какую особь указывает $start$ и выбираем эту особь: {0}
Потом сдвигаем указатель $start$ на $step$ вправо, смотрим на какую особь указывает указатель и записываем её в ответ: ${0, 0}$, итеративно повторяем инкрементацию step к указателю, пока он не выйдет за границы.
В результате получится такая выборка:
$$\{0, 0, 1, 1, 2, 3, 6\}$$
Хороших особей будем выбирать чаще (особи 0, 0, 1, 1), чем особей, которые в конце очереди убывания функции приспособленности. Хорошие особи попали по 2 раза в выборку, а остальные попали 1 раз или нисколько.
Причём каждый раз мы можем получать новую выборку, потому что $start$ выбирается случайно из диапазона $[0; step]$.

Когда мы решаем задачу с генетическим алгоритмом, то мы сами можем выбрать алгоритм селекции и отбора сильнейших особей по любому принципу, может он нам понравился.

#### Скрещивание (Crossover)
Взяли популяцию, убили половину, нужно эту половину восполнить. Волки должны скрещиваться для продолжения итеративности генетического алгоритма.
- Было предложено брать среднее для гена каждого волка - это применимо, когда гены особи - числовые признаки. А если гены категориальные - то это не сработает.
Пусть у нас есть 2 волка: $a$ и $b$. Мы решили, что каждый ген берём случайно.
Например, у обоих родителей 6 генов:
$$aaaaaa$$
$$bbbbbb$$
Мы выбираем гены обоих родителей случайно, получаем, например: $a a b a b b$. Этот метод называется **равномерным скрещиванием**, в результате его работы получается новый волк с генами от родителей a и b.

#### Одноточечный кроссовер
Пусть есть особь а и особь b, мы просто случайно проводим разделяющую линию, и меняем местами части:
$$a=[aaaaa|aa]$$
$$b =[bbbbb|bb]$$
В результате перемешивания получится:
$$ab =[aaaaa|bb]$$
и
$$ab= [bbbbb|aa]$$
#### k-точечный кроссовер 
Расставляем k разделителей, а потом, например, меняемся родительскими нечётными или чётными сегментами генов.

#### Факты
- Если 2 родителя производят слишком большое потомство, то популяция разбавляется их потомством и это может стать проблемой (однотипность генов).
- На самом деле можно использовать и 3-х, и 4-х, и 5 и так далее родителей для создания потомства.
- В результате скрещивания перестановок должна получиться перестановка (чтобы не было дубликатов).

#### Мутация
**Мутация** - это случайное изменение генов особей, чтобы изменить популяцию таким образом, чтобы она стала лучше.
Должен вводится шанс того, что особь мутирует (ген(ы) мутируют). 
Мутации применяются к особям появляющимся (не к родителям).
Мы хотим получить, например, 50 детей скрещиванием, а ещё 50 детей - мутацией. То-есть 50 детей получаются от 50 родителей (скрещиванием их генов), а остальные 50
получаются от изменения генов родителей.

В задачу можно ввести понятие пола, чтобы скрещивать только разнополых особей,
чтобы особи определённого пола имели только определённые хорошие признаки. Например, пусть мужчины умирают чаще, чем женщины, может быть это на что-то повлияет, вдруг более высокая частота смерти мужчин улучшает определённый ген мужчин, а у женщины он будет ниже качеством.
В задачу можно внести понятие **старения** - если особь часто выживает при селекции (выжила, например, 10 раз) - убиваем её. Но есть и другие способы их умертвления, например, если особь очень много информации внесла в популяцию (много потомства), предлагается её убить - это **смысл старения**.
Можно уменьшать функцию $fitness$ особи согласно её возрасту, например, на величину
$$\frac{1}{\frac{{max}_{возраст}}{возраст}}$$
Дополнительный метод решения: Пусть у нас есть 2 леса с волками, они развиваются независимо, а иногда волк мигрирует - это нужно, чтобы разбавлять популяции. Разделение на 2 леса называется **сегрегацией**.

У генетических алгоритмов есть тенденция cходиться к одному решению, поэтому предлагается получать 2 решения (или более) с помощью **сегрегации**.
**Сегрегацию** можно делать по кастам (группам), - допустим, особям из разных каст разрешить скрещиваться, но очень редко.

В результате всех итераций получается **набор лучших волков** (на самом деле их гены лучшие, а **гены - это параметры в решении**).
#### Вывод
**Генетический алгоритм** - это **творческий и гибкий** подход. Не существует единственного "правильного" набора параметров. Эффективность конкретных механизмов (*селекции, скрещивания, мутации*) сильно зависит от решаемой задачи. Это алгоритм *неградиентной оптимизации*, который ищет $fitness$ функцию путём моделирования эволюции жизни.
#### Ссылки
1. Лекции ИИБД 2025 ДВФУ - https://www.youtube.com/watch?v=xYrAev_Guao&list=PLWc6uq3QodNy5HX7zTTBXsJYWAwbw4q3M&index=8
2. [[Неградиентные методы оптимизации]] 