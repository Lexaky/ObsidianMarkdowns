**Created at** [01-12-2025 15:20]
**Tags**: #Математическая_статистика
# Эффект множественных сравнений. Введение в дисперсионный анализ. Множественные сравнения после ANOVA

#### Эффект множественных сравнений (multiple comaprisons || multiple testing)
Критерий Стьюдента для сравнения двух групп. Если большее количество - то у нас получается эффект множественных сравнений (попарно). Есть 3 выборки - нужно 3 раза сравнивать через t-test. 4 выборки - 6 сравнений. Общая формула:
$$\frac{N(N-1)}{2}$$
![[Эффект_множественных_сравнений_первый_слайд.png]]
При 3 выборках будет 3 сравнения. 
Вероятность отсутствия ошибки 1-го рода в одном из сравнений: $0.95^3 = 0.857$
Пусть $m$ - количество производимых сравнений.
$P_m = 1 - (1 - 0.05)^m = 1 - (1 - 0.05)^3 = 0.143$
$P_m \approx \alpha * m$ при небольших $m$.
И 3 - это не предел, если подставить в формулу: вероятность отсутствия ошибки 1-го рода:
$$1 - (1-0.05)^m$$
Задаёмся уровнем значимости $\alpha = 0.05$. Если сделаем $10$ сравнений, то это сильно повлияет на результат.

В 1950 году провели эксперимент по выявлению людей с экстрасенсорными способностями. Каждый испытуемый должен был угадать цвет каждой карты в последовательности из 10 карт.
Если все карты угаданы, то $P_{10} = 0.5^{10}$
Ни одной карты не угадали: $P_{10} = 0.5^{10}$
Девять карт: $P_9 = 0.5^9 * 0.5 + ... + 0.5^9 * 0.5 = 10 * 0.5^{10}$
Случайно угадать 9 или 10 карт из 10 составляет: $11 * 2^{-10} \approx 0.01$
Рейн считал наступление шанса свидетельством того, что испытуемый экстрасенс.
В опыте участвовало 1000 человек, вероятность того, что хотя бы один из 1000 человек угадает 9 или 10 карт:
$$1 - (1 - 11 * 2^{-10})^{1000} \approx 0.9998$$
На самом деле 12 человек угадали 9 из 10 карт, двое - все 10 карт.
В последующих экспериментах ни один из них не подтвердил свои способности.

#### Однофакторный дисперсионный анализ. Одновременное сравнение средних значений двух и более групп

Чтобы оценить величину различий, нужно сравнить: разброс выборочных средних с разбросом значений внутри групп. Это можно сделать с помощью дисперсии (показателя, характеризующего разброс).
Дисперсия правильно характеризует разброс только в том случае, если совокупность имеет нормальное распределение. 
Ограничения применения ANOVA:
* Нормальное распределение внутри групп;
* Дисперсии внутри групп не отличаются (гомоскедастичность).

Нулевая гипотеза - среднее во всех средних группах равны (все наблюдения всех групп происходят из одной нормально распределённой генеральной совокупности) - $H_0: \mu_1 = ... = \mu_k$. Если хотя бы одна отличается (одно из равенств нарушено), то это альтернатива (другая гипотеза).
$H_1$: в действительности наблюдаемые различия между групповыми средними несущественны и вызваны влиянием случайных факторов.

Строится 2 оценки дисперсии: 
Чем больше разброс средних и чем меньше разброс значений внутри групп, тем меньше вероятность того, что наши группы - это случайные выборки из одной совокупности.
Дисперсия, вычисленная для каждой группы - это оценка дисперсии совокупности. Дисперсию совокупности можно оценить на основании групповых дисперсий. Она не будет зависеть от различий групповых средних.
Разброс выборочных средних тоже позволяет оценить дисперсию совокупности. Зависит от различий выборочных средних.

Формально внутри- и межгрупповые дисперсии сравниваются с помощью $F$-критерия (он же критерий Фишера):
$$F = {MSB \over MSW}$$
$MSB$ - межгрупповая дисперсия, $MSW$ - внутригрупповая дисперсия.
Чем ближе $F$ к 1, тем меньше оснований утверждать, что внутри- и межгрупповая дисперсии различаются.
![[Эффект_множественных_сравнений_значениеF.png]]
Нулевая гипотеза отвергается, если $F > F_\alpha(df_B, df_W)$ - квантиль распределения Фишера с указанными степенями свободы.
$$F = {MSB\over MSW}$$
$$MSW = \sum_{i=1}^k s_i^2 \cdot {(n_i - 1)\over(n-k)}$$
$$MSB = \sum_{i=1}^k(\bar x_i - \bar x)^2 \cdot {n_i \over (k-1)}$$
Где $\bar x_i$ и $s_i^2$ - среднее и дисперсия по $i$-й группе, $\bar x$ - среднее по всем группам, $n_i$ - количество наблюдений в $i-й$ группе, $n$ - общее число наблюдений (по всем группам).
Число степеней свободы: $df_B = k-1, df_W = n-k$  -(Межгрупповая $k-1$, а внутригрупповая $n-k$)
Нулевая гипотеза отвергается, если $F > F_\alpha(df_B, df_W)$ - квантиль распределения Фишера с указанными степенями свободы.

Пример
Есть 3 группы людей с различным образом жизни.
Средние значения признака по группам: 
$$(11.5, 10.1, 9.1)$$
Выборочные стандартные отклонения:
$$(1.3, 2.1, 2.4)$$
Если выборок больше, чем 2 - сразу дисперсионный анализ. Отличаются ли средние в этих группах?
Групп 3, поэтому межгрупповых степеней свобод: $k-1 = 2$.
А внутригрупповых наблюдений: $n - k = 26 \cdot 3 - 3 = 75$
Среднее по всей выборке ${(11.5 + 10.1 + 9.1) \over 3} = 10.23$
Внутри и межгрупповые суммы квадратов отклонений:
$MSW = 296.5/75 = 3.95$
$MSB = 37.8$
$F = 37.8/3.95 = 9.56 // F(0.05, 2.75) = 3.12$ - наш больше, значит нулевую гипотезу отвергаем, которая заключалась в том, что они одинаковые - они на самом деле отличаются.

Если бы не отвергли 0-ю гипотезу (например при $\alpha = 0.5$, то дальше ничего не делаем, в анализе нет необходимости. А если нулевая гипотеза отвергается - то анализ продолжается. Спорт влияет, нужно делать post-hoc анализ (Апостериорный анализ). 
Какие именно группы статистически значимо отличаются друг от друга? - делаем попарные сравнения, но используем методы, обеспечивающие контроль над групповой вероятностью ошибки $1$-го рода.

#### Поправка Бонферрони. Множественные сравнения: апостериорный анализ
Простейший из методов множественных сравнений - это поправка Бонферрони.
Неравенство Бонферрони:
$$\alpha ^{'} < k \cdot \alpha$$
где $\alpha ^{'}$ - вероятность хотя бы один раз ошибочно выявить различия, если k раз применить критерии с уровнем значимости $\alpha$.
$\alpha^{'}$ - истинный уровень значимости многократно применённого критерия.
Если мы хотим обеспечить вероятность ошибки $\alpha^{'}$, то в каждом из сравнений мы должны принять уровень значимости:
$$\alpha^{'} \over k$$
Например, при трёхкратном сравнении уровень значимости должен быть ${0.05 \over 3} = 1.7\%$
Поправка Бонферрони хорошо работает, если число сравнений не превышает 8. Иначе метод становится слишком строгим и даже весьма большие различия приходится признавать статистически незначимыми.
`Для небольших групп не сильно влияет, а для больших сильно снижает мощность метода`.

#### Метод Холма - Бонферрони. Множественные сравнения апостериорный анализ
Более мощный метод, отчасти решает проблему падения мощности с ростом числа сравнений.
1. Исходные $p.values$ упорядочивают: $p_1 \le p_2 \le ... \le p_m$ (им соответствуют гипотезы $H_0(1), ..., H_0(m)$)
2. Если $p_1 \ge \frac \alpha m$, то принимаем все гипотезы ($H_0(1), ..., H_0(m)$) и останавливаемся.
3. Иначе отвергаем $H_0(1)$ и продолжаем проверку:
	1. Если $p_2 \ge \frac \alpha {m-1}$, то принимаем ($H_0(2), ..., H_0(m)$)и останавливаемся
	2. Иначе отвергаем $H_0(2)$ и продолжаем проверку: на каждом шаге корректируем поправку.
	3. В итоге к $m$-му шагу: $p_m \ge \alpha$

Пример: 3 попарных сравнения.
Получены $p: 0.005, 0.01, 0.02$
$p_1: 0.005 * 3 = 0.015 < 0.05 - H_0(1)$ отклоняем, есть различия
$p_2: 0.01 * 2 = 0.02 < 0.05$ отклоняем
$p_3: 0.02 * 1 = 0.02 <0.05$ отклоняем

#### Пример со спортсменами (продолжение)
t-критерии нашли, они соответствуют:
Малоактивные и физкультурники: $t = 1.6$
Малоактивные и спортсмены: $t = 4.48$
Физкультурники и спортсмены: $t = 2.89$
$t(0.05, 50) = 2.01$ и $t(0.017, 50) = 2.18$
$p.value$ у спортсменов, физкультурников и малоактивных: 0.11, 0.00007, 0.0077.

#### Критерий Тьюки
**Критерий Тьюки** - тоже критерий для множественных сравнений. Наиболее распространён и рекомендуем в литературе.
Использует критерий достоверно значимой разности HSD. HSD тест задаёт наименьшую величину разности математических ожиданий в группах, которую можно считать значимой. Позволяет рассчитать её доверительные интервалы с учётом числа выполняемых сравнений.

Нулевая гипотеза $H_0: \mu B = \mu A$
$H_1: \mu B \ne \mu A$
Где индексы $A$ и $B$ обозначают любые две сравниваемые группы. При наличии $m$ групп всего возможно выполнить $\frac m 2 (m-1)$ попарных сравнений.
$$q = {(\bar x_B - \bar x_A) \over SE}$$
$$SE = \sqrt \frac {MS_W} {n}$$
$MS_W$ - рассчитываемая в ходе дисперсионного анализа внутригрупповая дисперсия.

Тут гипотеза такая же, что средние не отличаются, две группы сравниваем. Хитрость в том, что у критерия Стьюдента - здесь смотрим на разницу средних, делим на разницу отклонений из формулы дисперсионного анализа.
Мощность критерия увеличивается.
Если сравниваемые группы неодинаковые по размеру, стандартная ошибка будет рассчитываться следующим образом:
$$SE = \sqrt {\frac {MS_W} {2} (\frac {1}{n_A} + \frac {1}{n_B})}$$
Статистика q в условиях нуль-гипотезы подчиняется так называемому распределению стьюдентизированных размахов.
Параметрами которого являются: общее число степеней свободы $N - k$, $N$ - общий объём всех выборок, $k$ - число групп.

Т.к. в формулу стандартной ошибки входит внутригрупповая дисперсия $MS_W$, критерий Тьюки подходит для выполнения большого числа парных сравнений групповых средних.

Критерий Тьюки имеет те же условия применимости, что и собственно дисперсионный анализ: нормальность распределения данных и однородность групповых дисперсия (гомоскедастичность).
Устойчивость к отклонению от этих условий, ровно как и статистическая мощность критерия Тьюки, возрастают при одинаковом числе наблюдений во всех сравниваемых группах.

#### Критерий Ньюмана-Кейлса

Используется критериальная статистика $q$ и распределение стьюдентизированных размахов - та же, что и в критерии Тьюки.
Сначала проводится процедура ранжирования групповых средних: от меньшего к большему.
Попарные сравнения:
* Сначала сравниваются наибольшее среднее с наименьшим, то-есть $1$-е с $k$-м.
* Затем $k$-е со $2$, далее с $3$-м и так далее до $(k-1)$-го.
* Затем предпоследнее ($k-1$)-е среднее сравнивается с $1$-м, $2$-м и так далее, пока не будут перебраны все пары средних.

Считается, что вывод, полученный при сравнении любой пары, можно распространить на весь диапазон групповых средних, которые заключен между ними.
Так, если не обнаружено отличий между $3$-м и $6$-м средними в упорядоченному ряду, то можно не проводить сравнения внутри интервала. Поэтому используется распределение стьюдентизированных размахов с число степеней свободы $N-k$  и числом групп, которые задается интервалом сравнения - I.
Интервал сравнения: $I = j-i+1$, (число позиций между сравниваемыми средними в упорядоченном ряду). Например, при сравнении 4-го и 1-го членов этого ряда: $I = 4 - 1 + 1 = 4$

При использовании критерия Тьюки всегда используется число имеющихся групп.
В результате, критерий Ньюмана-Кейлса и критерий Тьюки дадут одинаковые результаты только при сравнении наиболее контрастных групп, во всех остальных случаях критерий Ньюмана-Кейлса будет менее строгим.
Считается, что критерий Ньюмана-Кейлса излишне либерален и склонен выявлять ненадёжные отличия, поэтому в стандартных пакетах среды R он отсутствует.
Однако можно найти его реализации во множестве дополнительных пакетов, в частности в пакете mutoss.

#### Множественные сравнения с контрольной группой. Критерии Даннетта
Можно было бы использовать любой из методов, множественного сравнения: попарно сравнивать все группы, а затем отобрать те сравнения, в которых участвовала контрольная группа. Однако из-за большого числа лишних сравнений критические значение окажется неоправданно высоким: мы слишком часто будем пропускать реально существующие различия.
Критерий Даннетта - модификация критерия Тьюки или Ньюмана-Кейлса.
$$q = {(\bar x_B - \bar x_A)\over SE}$$
$$SE = \sqrt {\frac {MS_W}{2} (\frac 1 {n_A} + \frac 1 {n_B})}$$
Где A - контрольная группа. Параметр $I$ постоянен и равен числу групп, включая контрольную. Число степеней свобод $\nu = N - m$

Задание на практику:
1 задача про уровень холестерина - есть те, кто занимается спортом (средний по группе) у бегунов трусцой, марафонцев, 70 человек было в каждой группе. Нужно оценить статистическую значимость различий между группами. Есть ..., есть ..., столько-то человек. Просто сравниваем каждую с каждой...

Следующее - мед сёстра работают с разными больными, их на 3 группы разделили, первая группа - самая тяжёлая, третья - самая тяжёлая. Итого 6 групп по 16 медсестёр в каждой. У каждой своя степень выгорания (опустошённости) была. Средняя такая-то (там есть пропущенная запятая).
6 групп - всех сравнивать со всеми не нужно, просто сделать дисперсионный анализ - он может что-то сказать. А если есть, то всех сравнивать.

Следующее - таблица с данными по воздуху. Нужно понять, отличается ли температура воздуха от той, что была в сентябре?
Далее код R рассматриваем.


#### Ссылки
1. [Лекции по математическим методам анализа данных 2025]( https://cloud.mail.ru/public/T6ge/9337oqgK3)