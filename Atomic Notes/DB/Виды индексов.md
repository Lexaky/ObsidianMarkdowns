**Created at** [06-12-2025 10:14]
**Tags**: #Database 
# Виды индексов
Индексы нужны в одной базовой задаче - поиск чего-то в чём-то (одних данных в других в большом объёме). Книги "Искусство программирования - Дональд Кнут" разделены на 4, разделённых по базовым задачам:
1. **Основные алгоритмы** (Fundamental Algorithms) - структуры данных, математические введения, элементарные алгоритмы 
2. Поучительные алгоритмы
3. Сортировка и поиск
4. Комбинаторные алгоритмы - комбинации, перестановки, разбиения, деревья, графы, сети

Каждая книга посвящена конкретным задачам, которые встречаются и, в зависимости от задачи, составляются возможные решения и подводятся к конкретным алгоритмам решения.
Сортировка и поиск самая встречающаяся задача в текущих реалиях.
Существуют две разновидности поиска - **прямой** и **обратный**.
Прямой поиск осуществляется так: сканируется весь текст, смотрим в каком месте нашли.
Обратный поиск: предварительно нужно построить структуру данных, которая позволит
найти термы (единица структуры текста (или единица структуры битового массива)) в тексте. Если текст уже как-то обработан, то нам нужно составить по нему **реверсивный индекс** - эта структура бывает разной, но без неё ОП невозможен.
Если обычный индекс (прямой) говорит - в этом месте текста находится такой-то терм. Реверсивный индекс будет говорить о том, что терм содержится в таких-то блоках массива.
Простейший реверсивный индекс имеет следующую структуру:
1
По сортированному массиву можем бинарным поиском найти терм и сразу получить список его вхождений.

У гугла система barrel - это набор файликов, каждый файл - это барель, а вместе - это хранилище барелей. В каждом бареле 4 столбца, в каждом столбце наборы чисел следующие:
в 1 столбце (did - document id)
в 2 столбце (tid - term id)
В 3 столбце (offset - позиция)
В 4 столбце (bitmap - указывает в каком случае использовать или неиспользовать данный терм)
В зависимости от того, по какому из столбцов мы отсортируем набор баррелей - будет либо прямой индекс, либо обратный. Если сделать по возрастанию по did и tid, то получится прямой, если по tid и offset, то будет обратный индекс.
Изначально это весило у них 6 гб, а пересортировка в 2001 году занимала 200 минут на жёстком диске.
crowler - бегает по документу, потом бегает по всем ссылкам в дереве ссылок на определённую глубину. На тот момент 6 гб за 200 минут было нормально по времени отсортировать.
2
Внешняя сортировка отличается от внутренней тем, что внешняя - это с использованием внешних файлов (то-есть за пределы оперативной памяти)
Явное требование к сортировкам - внутренняя сортировка обязательно должна проводится только с использованием того массива данных (+-2 байт), которые нам предоставили. То-есть фактически там базовое действие - это замена.
Внешняя сортировка - это сортировка, которая использует дополнительную память, помимо той, которая была выделена под данные.
Сейчас барели не подходят из-за того, что у нас просто стало больше данных. 
В гугле сказали, что весь индекс они хранят уже давно в оперативной памяти.

Есть прямой индекс, есть реверсивный, ещё также есть:
1. Сортированный массив - Primary key
2. Деревья поиска (древовидные структуры) - в частности, B-tree.
3. hash, crypto-hash, perceptive-hash
4. Вероятностный индекс

Пример на основе бинарного дерева поиска (бывают n-нарные деревья поиска, это влияет на то, сколько потомков может быть у потомков). 
3
Есть корень, в нём есть число (некоторый номер n), в левом храним, всё, что меньше n, а в правом поддереве храним всё, что больше n. Т.о., БДП работают эффективно, если они **сбалансированные**.
Предположим, что у нас есть массив данных:
2,1,2,3,4,5,8,6,9,1,1
Нам нужно его запихнуть в дерево - можем банально поступить и взять первое число за корень дерева.
4

По-хорошему нужно отсортировать исходные данные и поставить в корень медиану.
Функции балансировки - тот функционал, который мы оптимизируем. Например, мы можем оптимизировать т. о., чтобы кол-во элементов слева и справа от корня отличалось не более, чем на 1 (это пример функционала балансировки), или должно быть минимальным (сильно балансированное дерево - есть эвристики, которые позволяют строить их сразу за проход). Heapsort или пирамидальная сортировка или сортировка кучами - это пример уже сбалансированных деревьев, они сбалансированы по глубине левого и правого поддерева.
Heap гарантирует, что дерево будет всегда такого вида:
5
и элементы будут отсутствовать снизу справа всегда (исчезать оттуда).
Строим кучу, а потом по-очереди вынимаем всегда корневой элемент (там всегда находится минимум). Мы можем не более чем за кол-во уровней поставить минимум (по какой-то теореме).

Сортировка и балансировка бывает разными, в зависимости от того, как мы делаем, получаем разные результата.
Для балансировки как правило используются RB tree.
Каждый узел дерева бывает либо красным, либо чёрным. Задача, чтобы красные листья соседствовали только с чёрными, на основании этого идёт балансировка.

#### B-tree
От бинарного дерева отличается только тем, что оно n-нарное. Оно хранит в себе структуры списочного вида.
У него неограниченное кол-во потомков, помимо этого хранится доп информация в узлах.
Узел имеет определённую структуру - это массив с некоторыми ссылками и значениями
В структуре директорий используются B-деревья. Всё, что находится в папке - это один узел B-дерева, всё что вложено - это вложенные B-деревья.
Поиск в этом дереве основан на правиле, по котором элементы в нём размещаются.
СУБД реализует B-дерево, можем ли мы как-то влиять на работу сортировки СУБД? - нет, через SQL нельзя, можно только создавать новый индекс.
6

Есть структура поиска, которая похожа на B-деревья, - **пространственная сетка**. Двумерная структура, у которой есть ячейки, есть 2 координаты (иногда 3).
7
Есть какое-то значение, которое надо найти, надо найти в какой ячейке сетки оно лежит. Имеем право упорядочивать данные в сетке.
Всю сетку можно рассматривать как элемент памяти. Представить структуру данных 3-чного дерева
8
Наша задача - привязать массив двумерный к разбиению множества.
9
Есть предложение - использовать комплексное число x + iy. Любая ячейка грида индексируется комплексным индексом. Есть успешное разбиение R3 - попытки соединения дерева индексом с Spatiel grid-tree и quart-tree. В четверном дереве номера ячеек дробятся вглубь. Сначала решётка делится на 4, потом внутри 0 снова идёт деление на 4 части, и так далее.

В дополнение как работать с комплексной записью x + iy: любой массив - есть функция FFT, есть обратная инверсная iFFT (объяснение в аудиозаписи на 47:00).


#### Хеши и хеш-индекс
Есть хеш-функции h(x) --> N, которая преобразует его в некоторое множество натуральных чисел. Возможна ситуация, когда h(x1) = N1 и h(x2) = N1 - это коллизия, которая никак не решается и позволяет хранить в одной ячейке одно значение для двух разных параметров.

**Закрытый хеш** - это когда в одну и ту же ячейку по функции попадают несколько значений, поэтому их начинаем линейно записывать в следующую ячейку.
Использовать связный список с сохранением в хеше - идея.

Крипто-хеш
Если расстояние между x1 и x2 маленькое: |x1 - x2| < eps, то мы гарантируем, что расстояние |h(x1) - h(x2)| > delta - незначительные изменения исходных данных влекут значительные изменения хеша.
При этом два икса которые отличаются сильно окажутся близко. При этом в сумме расстояние должно равняться примерно половине длины массива.

Есть perceptive-hash - это всё обратно: |x1 - x2| < eps --> |h(x1) - h(x2)| < delta. Этот хеш используется, когда нужно искать подобные (в гугле и яндексе так ищут картинки).

faiss - это про perceptive hash библиотека от facebook. От alibaba тоже есть какая-то. И там, и там - KNN используется.

#### Вероятностные индексы
Немного сложнее, но сильно быстрее.
Предположим, что массив настолько большой, что мы не можем позволить себе один раз его обойти - это дорого (даже линейный поиск медленный).
Вероятностный индекс имеет право ошибаться только в одну сторону - если он нашёл что-то, то это хорошо, а если не нашёл - это ни о чём не говорит.
Идея в предварительной обработке большого массива. Идея map reduce - если не можем бегать по всему массиву, то можем бегать по его частям. Сделаем модификацию с точным поиском.
Есть большой массив, что мы его разделили на 4 части и храним раздельно. Как можно организовать поиск? - через map reduce - организуем рассылку каждого элемента через map - каждому элементу говорим найти элемент с такими-то значениями. А потом редуцируем обратно - собираем ответы от каждого воркеров (рабочих). Каждый рабочий работает со своим кустом памяти (своей областью памяти). Если рабочий что-то нашёл, или если два рабочих нашли что-то, то мы склеиваем координаты и выдаём результаты.

Насколько параллельно мы можем обрабатывать массив? В случае поиска мы можем разбить на 200-300-500 частей, тогда мы получим обычный поиск, разделённый через map reduce.
вероятностный поиск получается в том случае, когда одна из частей большого массива обрабатывается тоже долго. Делим этот подмассив ещё на несколько частей (там принцип quicksort'а). Мы можем отсмотреть вглубь условно на 15 ходов. Таким образом, мы можем отсмотреть сколько элементов (дробя подмассивы пополам) и в глубину 15? -  15 вглубь - это значит что первый разбили на 2 части, потом внутренний на 2 части и т.д., то-есть 2^15 - если сможем оббежать этот подмассив, ... .
Если мы говорим, что дальше этой глубины идти не можем, то в этой глубине можем просто взять случайный элемент и сказать нашли или не нашли. В конечном итоге таким дроблением мы приходим к вероятностному индексу. В какой-то момент мы ищем на 15 шагов вглубь раздробив его. Мы можем 32768 элементов проверить случайным образом, дробя массив по какому-то признаку. Если признак окажется хорошо сортируемым, то можем сделать вывод не только об элементах, которые посмотрели, но и о тех, которые лежат близко от них.
Зависит от того, как построили изначальный массив. Если сможем сгруппировать его в каждом отдельном подмассиве нормально, то шанс найти повыситься вплоть до 100%. Минимальный шанс какой-то есть.
Здесь смысл в том, когда мы не можем обрабатывать массив целиком.

Про кэтс:
Кол-во попыток неограниченно, за неправильные решения нет штрафов.
Инциденты в техподдержке, остатки товаров на складе, и ещё какая-то - самые сложные задачи и интересные.
Идёт список инцидентов. Требуется найти 5 ближайших к устранению - у нас у каждого специалиста просто есть одно число, оно не говорит про номер задачи а только про номер устранённых инцидентов.
Прогресс обработки заявок - есть задача, они могут находиться в разных статусах (завершённая или новая). На каждый день нужно выдать кол-во задач, которые будут в статусах new и completed, при этом задача может находиться в любом статусе несколько дней и её можно переоткрывать неограниченное кол-во раз. Есть задачи, эти задачи отправляют в сервисный центр. Только поступившая отмечается new, завершившаяся completed, задача может перекидываться между статусами несколько раз. Это просто единый временной интервал и мне нужно в какие-то моменты времени отслеживать результат, то это вроде как простая задача.

Д/З:
Что подготовить для двух теоретических задач:
Логи сервера
дата время/ запрос get post put / заголовок / код ответа сервера / время обработки / id пользователя
Ключом скорее всего должно быть всё, кроме времени обработки. Либо вставить синтетический ключ - номер записи. На это обратить внимание при создании таблицы в clickhouse.
Можно в Python нагенерить несколько миллионов строк (до 2 гигабайт)

Clickhouse заводить с ядром merge 3. Ядро log не совсем правильно. У merge 3 нужно правильно настроить primary key. В PK входит определённый набор полей, этот набор полей обязательно должен быть уникальным. Если попробуем вставить 2 записи, у которых PK один и тот же, то они друг друга перезатрут

#### Ссылки
Source Material and other similar notes